<!DOCTYPE html>
<html>
<head>
	<link rel="stylesheet" href="style.css">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu">
	<link rel="icon" href="favicon.png">
	<title>Zachary R. McKee</title>
</head>
<body>
	<div id="wrapper">
			
		<header>
			<h1>Zachary R. McKee</h1>
			<div id="about">
				<p>Teaching Assistant for CS 350</p>
				<p>B.S. Computer Science -- Class of 2020</p>
				<p>Illinois Institute of Technology</p>
				<p><a href="resume9.pdf">Resume</a></p>
			</div>
		</header>
		<nav>
			<ul id="externalNav">
				<li><a href="https://www.linkedin.com/in/zacharyrmckee/">LinkedIn</a></li>
				<li><a href="https://github.com/ZacharyRMcKee">GitHub</a></li>
				<li><a href="https://devpost.com/ZacharyMcKee">Devpost</a></li>
				<li><p id="email">Email: zmckee@hawk.iit.edu</p></li>
			</ul>
		</nav>
		<div id="spacer"></div>
		<section id="main">
			<nav>
				<ul id="innerNav">
					<li><a href="index.html">Home</a></li>
					<li><a href="teaching.html">Teaching</a></li>
					<li><a id="currentPage" href="projects.html">Projects</a></li>
				</ul>

			</nav>
			<h2>Huffman Code Text Encoder/Decoder</h2>
			<p><a href="https://github.com/ZacharyRMcKee/Final-Spring17CS331">Source</a></p>
			<h3>Description</h3>
			<p>Text compression/decompression algorithm showcasing usage of trees, hash tables, object serialization, and algorithm design with performance in mind. What it does is take a text input consisting of ASCII characters, encodes it into a compressed file using the <a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman coding</a> algorithm, and then immediately takes that binary data and decodes it back into plaintext.</p>
			<h3>Performance Analysis</h3>
			<p>For the purposes of the assignment this project was developed for, this program is efficient enough. In order to analyze how well it performs with larger data sets, I went to the first large data set I could think of, which happened to be <a href="https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2">Chicago's reported crime data set.</a> I took progressively larger segments of this data, starting with relatively small samples (a few months' worth of data) and went up from there.</p>
			<div class="bk-root">
			    <div class="bk-plotdiv" id="7732b466-0f1c-4faa-8e06-8f17e36103a5"></div>
			</div>

			<figure>
			<img src="algorithmcomplexity.png" alt="Graph of a linear big-O complexity algorithm.">
			</figure>
			<p>Based off what this graph is telling us, we can conclude that the long-term
            complexity of this algorithm is &Theta;(n). This is desirable, however, as one can also
            see, the runtime for large data sets is suboptimal (around 24 minutes for 300MB of data),
            therefore there is a large constant factor.</p>
			<figure>
				<img src="profile.png" alt="Flame graph of Huffman Code Text Encoder/Decoder.">
				<figcaption>A <a href="http://www.brendangregg.com/flamegraphs.html">flame graph</a> of my program, showing the expense of decoding.</figcaption>
			</figure>
			<p>The two main portions of the program are called at line 21 of main.py (encoding)
			 and line 26 of main.py (decoding), which can be seen in the graph above, which displays
			 the stack frame of the program through its execution.</p>
			<p>Clearly, there is room for improvement. As can be seen above, the majority
            of the time spent is in the decoding portion of the program. The decoding portion uses a
            <strong>lot</strong> of recursive function calls in order to search the Huffman Tree as
            the program reads the encoded file. You can actually see the general shape of this recursion
			above, as new calls to traverseTree are pushed and popped to and from the stack.</p>
            <p>As function calls are relatively expensive, even in 
            C (because a new item on the runtime stack has to be created, stack pointer updated, etc), a good
            way to approach optimizing this algorithm would be re-implementing the tree-search portion of 
            the program in an iterative way. That way we're not asking the CPU to do all the miscellaneous tasks
            that are required to call a new Python function.</p>
            <p>Another thing that we want to be able to take advantage of when designing algorithms is the
            way the CPU is physically implemented. Unless Python is doing something truly amazing behind the scenes
            that I am not aware of, when we use a recursive implementation of tree searches, it's less likely
            for the data that we care about to be already stored in the cache when we request it
            (as the data is stored in a stack that potentially contains upwards of 10-20 seperate function calls,
            versus an iterative notation where we just have a pointer that gets changed as it goes down the tree).</p>
		
		</section>
		<footer>Zachary R. McKee &copy; 2017</footer>
	</div>
</body>
</html>
